<!-- SPDX-License-Identifier: CC-BY-SA-4.0 -->

# AI OSI Stack — Legal & Policy Outreach Brief

**Author:** Daniel P. Madden  
**Version:** v5.0  
**Repository:** [github.com/danielpmadden/ai-osi-stack](https://github.com/danielpmadden/ai-osi-stack)  
**Domain:** [aiosi.org](https://aiosi.org)  
**DOI:** [10.5281/zenodo.17517241](https://doi.org/10.5281/zenodo.17517241)  
**License:** CC BY-SA 4.0 (Docs) / Apache 2.0 (Code)

---

## Why This Exists

Artificial intelligence now operates faster than the law can interpret it.  
Every compliance regime — from ISO 42001 to the EU AI Act — depends on one missing ingredient: a **standardized way to prove what an AI system did, why it did it, and who authorized it.**

The AI OSI Stack solves that gap.  
It defines the architecture, evidence, and operational duties that make AI governance *verifiable* instead of aspirational.

---

## Why Lawyers and Policymakers Should Care

### 1. It Turns “Ethics” Into Enforceable Structure  
Most AI frameworks are declarations of intent.  
The Stack expresses those intents as testable duties, written in “SHALL / SHOULD / MAY” legal grammar, with direct links to machine-verifiable artefacts (AEIP schemas).  
It is **governance you can audit.**

### 2. It Provides an Evidentiary Chain of Custody  
Every decision, dataset, and model output is bound to a signed evidence record.  
This enables legal teams to reconstruct the provenance of any AI action — a requirement for liability, oversight, and redress.

### 3. It Makes Compliance Modular  
The Stack mirrors the OSI model: eight layers that map neatly to statute, regulation, policy, and procedure.  
Organizations can adopt one layer at a time and still gain measurable compliance value.

### 4. It Safeguards Human Agency  
The framework embeds interpretability and contestability directly into system design.  
It preserves the right of appeal and explanation — the human due process of AI.

### 5. It Creates Defensible Records  
The Stack generates artefacts that survive audit and litigation:  
hash-sealed manifests, signed decisions, and public disclosures.  
It replaces “we trust the system” with *here is the evidence.*

### 6. It’s Draftable Into Law  
Because it uses normative legal syntax and aligns with existing standards (ISO 42001, IEEE 7000, NIST AI RMF, EU AI Act Annex IV), entire sections can be adopted directly into legislation, certification, or policy.

### 7. It’s Commercially and Ethically Defensible  
Implementing the Stack reduces regulatory risk, increases disclosure readiness, and demonstrates ethical stewardship.  
It’s a public-interest safeguard that also protects institutional reputations and legal exposure.

---

## What It Offers

- **Architecture:** a layered, open-standard framework for AI accountability  
- **Runtime:** a Python “governance spine” implementing those layers  
- **Schemas:** machine-verifiable artefacts for every duty (AEIP v1.3)  
- **Dashboard:** a public-facing compliance and evidence interface  
- **Documentation:** legal-ready LaTeX source with clear normative grammar  

---

## What It Asks

- Engage in dialogue.  
- Pilot the Stack within your organization or jurisdiction.  
- Support its refinement through funded collaborations, audits, or legal research.

---

## Authorship & Provenance

The AI OSI Stack was conceived, authored, and maintained by **Daniel P. Madden** as an independent, self-funded project.  
There is no institutional, corporate, or governmental backing.  
All examples are synthetic; all standards references are alignment guides, not legal claims of compliance.

---

## Contact

- Website: [danielpmadden.com](https://danielpmadden.com)  
- Repository: [github.com/danielpmadden/ai-osi-stack](https://github.com/danielpmadden/ai-osi-stack)  
- DOI Record: [10.5281/zenodo.17517241](https://doi.org/10.5281/zenodo.17517241)  
- Domain: [aiosi.org](https://aiosi.org)

---
