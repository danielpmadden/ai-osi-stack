% SPDX-License-Identifier: CC-BY-NC-ND-4.0
\chapter{Layer 21 — Companion Trap}
\section{Narrative Intent}
Layer 21 addresses the risk that AI systems will be misperceived as companions or authorities, leading to
undue influence over individuals. The narrative intent is to preserve human agency and prevent dependency
patterns that undermine civic participation or well-being.

\section{Normative Clauses}
\begin{enumerate}
  \item \textbf{Boundary Signaling.} Interfaces SHALL clearly signal machine identity and limitations, avoiding
        anthropomorphic cues that could mislead users about autonomy or empathy.
  \item \textbf{Agency Safeguards.} Custodians SHALL provide easy exits, pause controls, and escalation pathways
        to human assistance when users seek guidance beyond the system’s remit.
  \item \textbf{Influence Monitoring.} Usage analytics SHALL monitor for dependency indicators—excessive
        session lengths, repeated sensitive disclosures—and trigger support interventions.
  \item \textbf{Vulnerable Population Protections.} Deployments in sensitive contexts (health, education,
        justice) SHALL incorporate additional consent checks and professional oversight.
\end{enumerate}

\section{Plain-Speak Summary}
This layer keeps the system from pretending to be a friend or counselor. It reminds people they are
interacting with a tool, gives them ways to disengage, watches for unhealthy dependency, and adds extra
checks when vulnerable groups are involved.

\cleardoublepage
